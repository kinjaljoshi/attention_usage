Understand and implement the attention mechanism
1. Attention in transformers
2. Self attention and masked attention
